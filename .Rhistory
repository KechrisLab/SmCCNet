}
}
}
if(length(penalty)==1) penalty <- rep(penalty, K)
if(sum(penalty<1 & type=="standard")){
stop("Cannot constrain sum of absolute values of weights to be less than
1.")
}
for(i in seq_len(K-1)){
if(type[i]=="standard" && penalty[i]>sqrt(ncol(xlist[[i]]))){
stop("L1 bound of weights should be no more than sqrt of the number of
columns of the corresponding data set.", fill=TRUE)
}
}
ws.final <- ws.init
for(i in seq_len(K-1)){
ws.final[[i]] <- matrix(0, nrow=ncol(xlist[[i]]), ncol=ncomponents)
}
cors <- NULL
for(comp in seq_len(ncomponents)){
ws <- list()
for(i in seq_len(K-1)) ws[[i]] <- ws.init[[i]][,comp]
ws[[K]] <- 1
curiter <- 1
crit.old <- -10
crit <- -20
storecrits <- NULL
while(curiter<=niter && abs(crit.old-crit)/abs(crit.old)>.001 &&
crit.old!=0){
crit.old <- crit
crit <- myGetCrit(xlist, ws, pair_CC, CCcoef)
storecrits <- c(storecrits,crit)
if(trace) cat(curiter, fill=FALSE)
curiter <- curiter+1
for(i in seq_len(K-1)){
ws[[i]] <- myUpdateW(xlist, i, K, penalty[i], ws, type[i], ws.final,
pair_CC, CCcoef)
}
}
for(i in seq_len(K-1)) ws.final[[i]][,comp] <- ws[[i]]
cors <- c(cors, myGetCors(xlist, ws, pair_CC, CCcoef))
}
out <- list(ws=ws.final, ws.init=ws.init, K=K, call=call, type=type,
penalty=penalty, cors=cors)
class(out) <- "MultiCCA"
}
return(out)
}
out <- myMultiCCA(X, penalty = L,
CCcoef = CCcoef, trace = trace)
out <- myMultiCCA(X, penalty = L,
CCcoef = CCcoef, trace = FALSE)
View(out)
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::document()
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::build(args = "--compact-vignettes=gs+qpdf")
knitr::opts_chunk$set(echo = TRUE)
library(pbapply)
library(Matrix)
library(igraph)
library(SmCCNet)
library(furrr)
library(future)
data(ExampleData)
head(X1[ , 1:6])
head(X2[ , 1:6])
head(Y)
p1 <- ncol(X1)
p2 <- ncol(X2)
n <- nrow(X1)
AbarLabel <- c(colnames(cbind(X1, X2)))
# define data list
X <- list(X1, X2)
# preprocess data
processed_data <- lapply(X, function(Xmatrix){
as.matrix(dataPreprocess(X = as.data.frame(Xmatrix), covariates = NULL,
is_cv = TRUE, cv_quantile = 0.2, center = TRUE,
scale = TRUE))})
# number of folds in K-fold CV.
K <- 3
N <- nrow(X1)
# create a list of omics data **
X <- list(X1, X2)
# number of omics dataset **
num_omics <- 2
# tuning parameter candidate length for each omics data
tuneLength <- 5
# tuning parameter candadate range for each omics data
minTune <- 0.1
maxTune <- 0.5
# create empty matrix to store all possible penalty parameters
penSelect <- matrix(0, nrow = tuneLength, ncol = num_omics)
# create sparsity penalty options.
for (Idx in 1:ncol(penSelect))
{
penSelect[,Idx] <- seq(from = minTune,
to = maxTune,
length.out = tuneLength)
}
# expand grid
# convert matrix to list of columns
list_cols <- as.list(as.data.frame(penSelect))
# generate all possible combinations
PenExpand <- do.call(expand.grid, list_cols)
# set a CV directory.
CVDir <- "Example3foldCV/"
dir.create(CVDir)
# re-standardize -omics data if regress-out approach is used (covariates != NULL)
processed_data <- lapply(processed_data, scale)
set.seed(12345) # set random seed.
# split data into folds
foldIdx <- suppressWarnings(split(1:nrow(X[[1]]), sample(1:nrow(X[[1]]), K)))
folddata <- purrr::map(1:length(foldIdx), function(x){
Y <- as.matrix(Y)
X_train <- list()
X_test <- list()
Y_train <- list()
Y_test <- list()
for (i in 1:length(X))
{
X_train[[i]] <- scale(X[[i]][-foldIdx[[x]],])
X_test[[i]] <- scale(X[[i]][foldIdx[[x]],])
}
Y_train <- scale(Y[-foldIdx[[x]],])
Y_test <- scale(Y[foldIdx[[x]],])
return(list(X_train = X_train, X_test = X_test,Y_train = Y_train,
Y_test = Y_test))
})
# name each fold of data
names(folddata) <- paste0('Fold_', 1:K)
# saving all preliminary data into local directory for reproducibility purpose
save(folddata, PenExpand,
file = paste0(CVDir, "CVData.RData"))
# default
scalingFactor <- rep(1,ncol(combn(num_omics + 1,2)))
# interactive **
scalingFactor <- scalingFactorInput(DataType = c('mRNA', 'miRNA', 'phenotype'))
# load cross-validation data
load(paste0(CVDir, "CVData.RData"))
# create an empty list for storing CV result for each fold
CVResult <- list()
for (CVidx in 1:K)
{
# set scaling factor
CCcoef <- scalingFactor
# create empty vector for storing cross-validation result
RhoTrain <- RhoTest <- DeltaCor <- rep(0, nrow(PenExpand))
for(idx in 1:nrow(PenExpand))
{
# consider one pair of sparsity penalties at a time.
l <- PenExpand[idx, ]
# run SmCCA on the subsamples (Figure 1, Step II)
Ws <- getCanWeightsMulti(folddata[[CVidx]][["X_train"]],
Trait = as.matrix(folddata[[CVidx]][["Y_train"]]),
Lambda = as.numeric(l), NoTrait = FALSE,
CCcoef = CCcoef)
# evaluate the canonical correlation for training and testing data
rho.train <-  getCanCorMulti(X = folddata[[CVidx]][["X_train"]],
Y = as.matrix(folddata[[CVidx]][["Y_train"]]),
CCWeight = Ws,
CCcoef = CCcoef)
rho.test <-  getCanCorMulti(X = folddata[[CVidx]][["X_test"]],
Y = as.matrix(folddata[[CVidx]][["Y_test"]]),
CCWeight = Ws,
CCcoef = CCcoef)
# store cv result
RhoTrain[idx] <- round(rho.train, digits = 5)
RhoTest[idx] <- round(rho.test, digits = 5)
DeltaCor[idx] <- abs(rho.train - rho.test)
}
# record prediction errors for given CV fold and all sparsity penalty
# options.
CVResult[[CVidx]] <- cbind(RhoTrain, RhoTest, DeltaCor)
}
# aggregate CV result and select the best penalty term
AggregatedCVResult <- Reduce("+", CVResult) / length(CVResult)
# calculate the evaluation metric of interest
EvalMetric <- apply(AggregatedCVResult, 1, function(x) {x[3]/abs(x[2])})
# determine the best CV result
optIdx <- which.min(EvalMetric)
library(plotly)
library(reshape2)
f1 <- list(
family = "Arial, sans-serif",
size = 20,
color = "black"
)
f2 <- list(
family = "Old Standard TT, serif",
size = 20,
color = "black"
)
a <- list(
title = "l1",
titlefont = f1,
showticklabels = TRUE,
tickfont = f2
)
b <- list(
title = "l2",
titlefont = f1,
showticklabels = TRUE,
tickfont = f2
)
# create melt data
PenExpandMelt <- cbind(PenExpand[,c(1,2)], EvalMetric)
colnames(PenExpandMelt)[c(1,2)] <- c('l1', 'l2')
hmelt <- melt(PenExpandMelt, id.vars = c("l1", "l2"))
contourPlot <- plot_ly(hmelt, x = ~l1, y = ~l2, z = ~value,
type = "contour") %>%
layout(xaxis = a, yaxis = b, showlegend = TRUE, legend = f1)
# orca preinstalltion is required for next step:
# https://github.com/plotly/orca#installation
contourPlot
# combine CV evaluation result with penalty candidates
overallCVInfo <- cbind(PenExpand, AggregatedCVResult, scaledPredError = EvalMetric)
# set column names for penalty terms
colnames(overallCVInfo)[1:num_omics] <- paste0('l',1:num_omics)
# save overall CV result
write.csv(overallCVInfo, file = paste0(CVDir, 'overallCVInfo.csv'),
row.names = FALSE)
# print out the best CV penalty pair and associated result
print(overallCVInfo[optIdx,])
# feature sampling proportions, 0.9 for miRNA since it has less features. **
s <- c(0.7,0.9)
# number of subsamples.
SubsamplingNum <- 50
# run SmCCA on the subsamples (Figure 1, Step II)
Ws <- getRobustWeightsMulti(X,
Trait = as.matrix(Y),
NoTrait = FALSE,CCcoef = scalingFactor,
Lambda = as.numeric(overallCVInfo[optIdx,1:num_omics]),
s = s,
SubsamplingNum = SubsamplingNum)
# number of folds in K-fold CV.
K <- 3
N <- nrow(X1)
# create a list of omics data
X <- list(X1, X2)
# number of omics dataset
num_omics <- 2
# tuning parameter candidate length for each omics data
tuneLength <- 5
# tuning parameter candadate range for each omics data
minTune <- 0.1
maxTune <- 0.5
# create empty matrix to store all possible penalty parameters
penSelect <- matrix(0, nrow = tuneLength, ncol = num_omics)
# create sparsity penalty options.
for (Idx in 1:ncol(penSelect))
{
penSelect[,Idx] <- seq(from = minTune,
to = maxTune,
length.out = tuneLength)
}
# expand grid
# convert matrix to list of columns
list_cols <- as.list(as.data.frame(penSelect))
# generate all possible combinations
PenExpand <- do.call(expand.grid, list_cols)
# set a CV directory.
CVDir <- "Example3foldCVTune/"
dir.create(CVDir)
data(ExampleData)
head(X1[ , 1:6])
head(X2[ , 1:6])
# binarize phenotype variable
Y <- ifelse(Y > median(Y), 1, 0)
head(Y)
p1 <- ncol(X1)
p2 <- ncol(X2)
n <- nrow(X1)
AbarLabel <- c(colnames(cbind(X1, X2)))
# number of folds in K-fold CV.
K <- 3
N <- nrow(X1)
# create a list of omics data
X <- list(X1, X2)
# number of component for PLS
ncomp <- 3
# number of omics dataset
num_omics <- 2
# tuning parameter candidate length for each omics data
tuneLength <- 5
# tuning parameter candadate range for each omics data
minTune <- 0.1
maxTune <- 0.5
# create empty matrix to store all possible penalty parameters
penSelect <- matrix(0, nrow = tuneLength, ncol = num_omics)
# set up the evaluation metric (choose between 'accuracy', 'auc', 'precision',
# 'recall', 'f1')
metric <- 'auc'
# create sparsity penalty options.
for (Idx in 1:ncol(penSelect))
{
penSelect[,Idx] <- seq(from = minTune,
to = maxTune,
length.out = tuneLength)
}
# combine with penalty term for classifier
penSelect <- cbind(penSelect, seq(from = 0.5,
to = 0.9,
length.out = tuneLength))
# expand grid
# convert matrix to list of columns
list_cols <- as.list(as.data.frame(penSelect))
# generate all possible combinations
PenExpand <- do.call(expand.grid, list_cols)
# set a CV directory.
CVDir <- "Example3foldCVBinary/"
dir.create(CVDir)
set.seed(12345) # set random seed.
# split data into folds
X <- lapply(X, scale)
foldIdx <- suppressWarnings(split(1:nrow(X[[1]]), sample(1:nrow(X[[1]]), K)))
folddata <- purrr::map(1:length(foldIdx), function(x){
Y <- as.matrix(Y)
X_train <- list()
X_test <- list()
Y_train <- list()
Y_test <- list()
for (i in 1:length(X))
{
X_train[[i]] <- X[[i]][-foldIdx[[x]],]
X_test[[i]] <- X[[i]][foldIdx[[x]],]
}
Y_train <- Y[-foldIdx[[x]],]
Y_test <- Y[foldIdx[[x]],]
return(list(X_train = X_train, X_test = X_test,Y_train = Y_train,
Y_test = Y_test))
})
# name each fold of data
names(folddata) <- paste0('Fold_', 1:K)
# saving all preliminary data into local directory for reproducibility purpose
save(folddata, PenExpand,
file = paste0(CVDir, "CVData.RData"))
scalingFactor <- 1
scalingFactor <- scalingFactorInput(c('mRNA', 'miRNA'))
# create an empty list to store the cv result
CVResult <- list()
# load cross-validation data
load(paste0(CVDir, "CVData.RData"))
for (CVidx in 1:K)
{
CCcoef <- scalingFactor
TrainScore <- TestScore <- rep(0, nrow(PenExpand))
for(idx in 1:nrow(PenExpand)){
# consider one pair of sparsity penalties at a time.
l <- PenExpand[idx, ]
# run multi-block PLS
CCcoef <- scalingFactor
# run multi-block PLS
suppressMessages(projection <- getRobustWeightsMultiBinary(
folddata[[CVidx]][["X_train"]],
as.numeric(folddata[[CVidx]][["Y_train"]]),
SubsamplingPercent=c(1,1),
Between_Discriminate_Ratio = c(1,1),
LambdaBetween = l[1,1:num_omics],
LambdaPheno = l[1,(num_omics + 1)],
SubsamplingNum = 1,
CCcoef = CCcoef,
ncomp_pls = ncomp, EvalClassifier = TRUE,
testData = folddata[[CVidx]][["X_test"]]))
# create training and testing data, and fit logistic regression model
train_data <- data.frame(x = projection[[1]],
y = as.factor(folddata[[CVidx]][["Y_train"]]))
test_data <- data.frame(x =  projection[[2]])
# catching error when performing the logistic regression
has_error <- FALSE
suppressWarnings(
tryCatch({
# fit logistic regression model
logisticFit <- stats::glm(y ~ ., family = 'binomial', data = train_data)
# make prediction for train/test set
train_pred <- stats::predict(logisticFit, train_data, type = 'response')
test_pred <- stats::predict(logisticFit, test_data, type = 'response')
train_score <- classifierEval(obs = folddata[[CVidx]][["Y_train"]],
pred = train_pred,
EvalMethod = metric, print_score = FALSE)
test_score <- classifierEval(obs = folddata[[CVidx]][["Y_test"]],
pred = test_pred,
EvalMethod = metric, print_score = FALSE)
},
error = function(e) {
cat("Caught an error:", e$message, "\n")
has_error <- TRUE
})
)
TrainScore[idx] <- round(train_score, digits = 5)
TestScore[idx] <- round(test_score, digits = 5)
}
# record prediction errors for given CV fold and all sparsity penalty
# options.
CVResult[[CVidx]] <- cbind(TrainScore, TestScore)
}
# aggregate CV result and select the best penalty term
AggregatedCVResult <- Reduce("+", CVResult) / length(CVResult)
# determine the best CV result
optIdx <- which.max(AggregatedCVResult[,2])
View(AggregatedCVResult)
# combine CV evaluation result with penalty candidates
overallCVInfo <- cbind(PenExpand, AggregatedCVResult)
# set column names for penalty terms for omics
colnames(overallCVInfo)[1:num_omics] <- paste0('l',1:num_omics)
# set column names for penalty terms for classifier
colnames(overallCVInfo)[num_omics+1] <- paste0('lpheno')
# save overall CV result
write.csv(overallCVInfo, file = paste0(CVDir, 'overallCVInfo.csv'),
row.names = FALSE)
# print out the best CV penalty pair and associated result
print(overallCVInfo[optIdx,])
# feature sampling proportions, 0.9 for miRNA since it has less features.
s <- c(0.7,0.9)
# number of subsamples.
SubsamplingNum <- 50
# run SPLSDA on the subsamples
Ws <- getRobustWeightsMultiBinary(X,
as.numeric(Y),
SubsamplingPercent=s,
Between_Discriminate_Ratio = c(1,1),
LambdaBetween = as.numeric(overallCVInfo[optIdx,1:num_omics]),
LambdaPheno = as.numeric(overallCVInfo[optIdx,num_omics + 1]),
SubsamplingNum = SubsamplingNum,
CCcoef = scalingFactor,
ncomp_pls = ncomp, EvalClassifier = FALSE)
View(Ws)
# define data list
X <- list(X1, X2)
# preprocess data
processed_data <- lapply(X, function(Xmatrix){
as.matrix(dataPreprocess(X = as.data.frame(Xmatrix), covariates = NULL,
is_cv = TRUE, cv_quantile = 0.2, center = TRUE,
scale = TRUE))})
# re-standardize -omics data if regress-out approach is used (covariates != NULL)
processed_data <- lapply(processed_data, scale)
# if preprocess feature is used, X need to be overrided with the following code
X <- processed_data
knitr::opts_chunk$set(echo = TRUE)
library(SmCCNet)
set.seed(123)
data("ExampleData")
# single-omics PLS
result <- fastAutoSmCCNet(X = list(X1), Y = as.factor(Y_binary),
Kfold = 3,
subSampNum = 100, DataType = c('Gene'),
saving_dir = getwd(), EvalMethod = 'auc',
summarization = 'NetSHy',
CutHeight = 1 - 0.1^10, ncomp_pls = 5)
Y_binary <- ifelse(Y > quantile(Y, 0.5), 1, 0)
# single-omics PLS
result <- fastAutoSmCCNet(X = list(X1), Y = as.factor(Y_binary),
Kfold = 3,
subSampNum = 100, DataType = c('Gene'),
saving_dir = getwd(), EvalMethod = 'auc',
summarization = 'NetSHy',
CutHeight = 1 - 0.1^10, ncomp_pls = 5)
# single-omics CCA
result <- fastAutoSmCCNet(X = list(X1), Y = Y, Kfold = 3,
preprocess = FALSE,
subSampNum = 50, DataType = c('Gene'),
saving_dir = getwd(), summarization = 'PCA',
CutHeight = 1 - 0.1^10)
# multi-omics PLS
result <- fastAutoSmCCNet(X = list(X1,X2), Y = as.factor(Y_binary),
Kfold = 3, subSampNum = 50,
DataType = c('Gene', 'miRNA'),
CutHeight = 1 - 0.1^10,
saving_dir = getwd(),
EvalMethod = 'auc',
summarization = 'NetSHy',
BetweenShrinkage = 5,
ncomp_pls = 3)
# multi-omics CCA
result <- fastAutoSmCCNet(X = list(X1,X2), Y = Y,
K = 3, subSampNum = 50,
DataType = c('Gene', 'miRNA'),
CutHeight = 1 - 0.1^10,
saving_dir = getwd(),
summarization = 'NetSHy',
BetweenShrinkage = 5)
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::build_vignettes()
devtools::build_vignettes()
devtools::build_readme()
devtools::build_readme()
?devtools::build_site
devtools::build_site()
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::build_site()
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::build_site()
devtools::build_vignettes()
?devtools::build_site
devtools::build_site()
?devtools::build_site
devtools::build_site()
devtools::build_vignettes()
devtools::build_vignettes()
devtools::build_vignettes()
devtools::build_site()
devtools::build_vignettes()
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::build_vignettes()
devtools::build_vignettes()
devtools::check(build_args = "--compact-vignettes=gs+qpdf")
devtools::build(args = "--compact-vignettes=gs+qpdf")
devtools::build_site()
usethis::use_pkgdown_github_pages()
